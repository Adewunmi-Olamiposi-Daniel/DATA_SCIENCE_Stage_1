DSWK3D1-Working-with-Files

DAY 1, WEEK 3, MONDAY NOV 10

ðŸ§­ DSWK3 â€“ Working with Files and Modules

ðŸ“… Week 3 Begins (Mon, Nov 10 â€“ Sat, Nov 15)

ðŸ”¹ WHAT I LEARNT TODAY

Today introduced me to file handling in Python, a core skill every data scientist needs because almost all real-world data is stored in files. I learned how to work with text files, from creating new ones to updating existing ones.

Specifically, I learned:

How to open a file using open(path, mode)

The 3 main modes:

"w" write mode (creates or overwrites a file)

"a" append mode (adds new data at the end)

"r" read mode (opens a file for reading)

How to write text into a file

How to append new content without deleting old content

How to read everything inside a file using .read()

How to handle multiline text using triple quotes

Why context managers (with open(...) as f:) are the safest and most professional way to work with files

This was my first step into understanding how Python interacts with the real world through storage.

ðŸ’» MY PRACTICE HIGHLIGHTS

Throughout todayâ€™s lesson, I:

Created a text file and wrote an introduction about myself into it

Appended extra sentences to the same file using "a"

Used a context manager to add additional lines in a clean, safe way

Read the file back into Python and printed its full contents

Wrote a multiline message using triple-quoted strings

Confirmed my updates by printing the final version of the file again

All these steps showed me how flexible, powerful and simple Python file operations can be.

ðŸ’­ REFLECTION

Working with files felt like opening a direct door to the outside world. Instead of everything happening inside Python, I finally interacted with real storage. It made the code feel more alive, like something that remembered what I wrote.

The biggest lesson today is that file handling is not complicated. It is mostly about understanding the mode you are using and knowing when to use a context manager.

This skill will be important later when I start handling CSV data, logs, datasets and automation tasks. Today was just text files, but it already feels like building the foundation for real data projects.
